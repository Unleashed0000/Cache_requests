# Cache_requests
## Информация о команде: ее название и фамилии участников на момент отправки кода
# Команда QuinQuaQuo
Николай Филинов - backend <br>
Владимир Петров - backend <br>
Аня Умикашвили - Project manager <br>
Надежда Агафонова - Project manager <br>

# requirements
python 3.10.9
pip install fastapi, redis, uvicorn, xmltodict, socket

## БД redis 
В данный момент запущена на нашем удалённом сервере и вам поднимать её не нужно

### to start in termnial
Более подробный локальнйы запуск будет описан в видео демонстрации <br>
<code> uvicorn main:app --reload </code>
<code> uvicorn main:app --port 5000 --host '0.0.0.0' --reload </code>

# Структура проекта
![image](https://github.com/Unleashed0000/Cache_requests/assets/31584866/4d6af356-65c1-4155-9ba6-67dc68297dfa)

# Видео фиксация корректности разработанного приложения, проверка через Wireshark
https://youtu.be/ixSV4lsoHLA
# Описание разработанного приложения
Приложение редставляет собой MVP промежуточного сервиса — прокси-эмулятора, который встает между приложениями в тестовой среде и тестовой средой партнеров.
Логика работы приложения следующая:
1. На API приходит инициализирующий запрос  /post/initial, в котором содержится следующая информация:
   1. url_ext - url тестовой среды, на которую следует перенаправлять запросы
   2. exclude_columns (Опционально) - поля которые отличаются у запросов которые можно считать одинаковыми
   3. key_columns (Опционально) - поля, различие по которым важно.
   4. database (Опционально) - выбранная база данных   
   5. use_exclude_columns (Опционально) - флаг для выбора режима формирования ключа кэша (Убирать exclude columns, или оставлять только key columns)
   6. headers (Опционально) - Headers для GET запросов, данный установленный headers будет использоваться в GET запросах к url_ext. 

   Пример:
   data_initial = {
    "url": f"http://{host_port}/post/initial",
    "url_ext": "https://vk.com/",
    "exclude_columns":['id','url'],
    "key_columns":['car_number','card_cvc'],
    "database": "Redis",
    "use_exclude_columns": True,
    "headers":{"Content-Type": "application/json"}}
   
3. Последующие запросы содержат в себе:
Для GET запросов, указывается лишь database для выбора базы данных (По умолчанию Redis, если без параметров.), data_get["url"] - это url нашего прокси для прокидывания запроса через него.
requests.get(data_get["url"]+"?database="+data_get["database"])
Для POST и PUT запросов, вызов выглядит следующим образом:
requests.post(data_initial["url"],json=data_initial)
Приложение позволяет так же делать запросы не с JSON, а с XML данными:
requests.post(url,data=data_xml)  
Важно использовать корректные API для ваших данных:
POST с JSON /post/json
POST с XML - /post
PUT с XML - /put
PUT с JSON - /put/json

При получении запроса, прокси сервер проверяет существует ли такой кэш в базе данных, если существует - возвращает ранее полученный response, если не существует - выполняется запрос.

3. Рассмотрен вариант обработки коллбэков, в частности в модуле request_handler.py добавлена ф-ция для отправки сообщений, с учетом того, что может прийти коллбэк
Логика работы:  Отправляем сообщение тест-среде через сокет, некоторое время (5сек) сокет считывает все приходящие сообщения 
Все полученные сообщения кэшируются и записываются в базу.  Ключом является строка url
key-callback - наборей полей по которому определяется какому именно сообщению принадлежит колл-бэк
Сейчас ф-ция работает синхронно т.е. в один момент времени только 1 сокет открыт, поэтому поле <id>
не требуется для распознавания сообщения, в каждый момент сокет слушает только 1 сервер, поэтому все ответы он относит к отправленному сообщению.
Можно сделать асинхронно, чтобы открывалось несколько сокетов сразу, и новые сообщения добавлялись только по ключевым полям.
Функция - make_request_socket(url, method, headers,body={},database="Redis",exclude=[],key=[],flag = True,key_callback=['id'])

